{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://towardsdatascience.com/feature-selection-using-python-for-classification-problem-b5f00a1c7028#:~:text=Univariate%20feature%20selection%20works%20by,analysis%20of%20variance%20(ANOVA).&text=That%20is%20why%20it%20is%20called%20'univariate'.\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VARIANCE THRESHOLD to remove features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 0, 1], [0, 1, 0], [1, 0, 0], [0, 1, 1], [0, 1, 0], [0, 1, 1]]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "X = [[0, 0, 1], [0, 1, 0], [1, 0, 0], [0, 1, 1], [0, 1, 0], [0, 1, 1]]\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1],\n",
       "       [1, 0],\n",
       "       [0, 0],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [1, 1]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove all features that are either one or zero (on or off) in more than 80% of the samples\n",
    "sel = VarianceThreshold(threshold=(.8 * (1 - .8)))\n",
    "sel.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 4)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "X, y = load_iris(return_X_y=True)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SELECT K BEST and chi squared to remove features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove features based on chi squared scores\n",
    "# Recall that the chi-square test measures dependence between stochastic variables, so using this function “weeds out” the features that are the most likely to be independent of class and therefore irrelevant for classification.\n",
    "X_new = SelectKBest(chi2, k=2).fit_transform(X, y)\n",
    "X_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNIVARIATE FEATURE SELECTION and f scores from ANOVA to remove features (looks at one feature at a time and its relationship to output)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.feature_selection import SelectKBest, f_classif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import some data to play with\n",
    "\n",
    "# The iris dataset\n",
    "X, y = load_iris(return_X_y=True)\n",
    "\n",
    "# Some noisy data not correlated\n",
    "E = np.random.RandomState(42).uniform(0, 0.1, size=(X.shape[0], 20))\n",
    "\n",
    "# Add the noisy data to the informative features\n",
    "X = np.hstack((X, E))\n",
    "\n",
    "# Split dataset to select feature and evaluate the classifier\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=0)\n",
    "\n",
    "plt.figure(1)\n",
    "plt.clf()\n",
    "\n",
    "X_indices = np.arange(X.shape[-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification accuracy without selecting features: 0.789\n",
      "Classification accuracy after univariate feature selection: 0.868\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# #############################################################################\n",
    "# Univariate feature selection with F-test for feature scoring\n",
    "# We use the default selection function to select the four\n",
    "# most significant features\n",
    "selector = SelectKBest(f_classif, k=4)\n",
    "selector.fit(X_train, y_train)\n",
    "scores = -np.log10(selector.pvalues_)\n",
    "scores /= scores.max()\n",
    "plt.bar(\n",
    "    X_indices - 0.45, scores, width=0.2, label=r\"Univariate score ($-Log(p_{value})$)\"\n",
    ")\n",
    "\n",
    "# #############################################################################\n",
    "# Compare to the weights of an SVM\n",
    "clf = make_pipeline(MinMaxScaler(), LinearSVC())\n",
    "clf.fit(X_train, y_train)\n",
    "print(\n",
    "    \"Classification accuracy without selecting features: {:.3f}\".format(\n",
    "        clf.score(X_test, y_test)\n",
    "    )\n",
    ")\n",
    "\n",
    "svm_weights = np.abs(clf[-1].coef_).sum(axis=0)\n",
    "svm_weights /= svm_weights.sum()\n",
    "\n",
    "plt.bar(X_indices - 0.25, svm_weights, width=0.2, label=\"SVM weight\")\n",
    "\n",
    "#uses f score from ANOVAS to choose best 4 features \n",
    "clf_selected = make_pipeline(SelectKBest(f_classif, k=4), MinMaxScaler(), LinearSVC())\n",
    "clf_selected.fit(X_train, y_train)\n",
    "print(\n",
    "    \"Classification accuracy after univariate feature selection: {:.3f}\".format(\n",
    "        clf_selected.score(X_test, y_test)\n",
    "    )\n",
    ")\n",
    "\n",
    "svm_weights_selected = np.abs(clf_selected[-1].coef_).sum(axis=0)\n",
    "svm_weights_selected /= svm_weights_selected.sum()\n",
    "\n",
    "plt.bar(\n",
    "    X_indices[selector.get_support()] - 0.05,\n",
    "    svm_weights_selected,\n",
    "    width=0.2,\n",
    "    label=\"SVM weights after selection\",\n",
    ")\n",
    "\n",
    "\n",
    "plt.title(\"Comparing feature selection\")\n",
    "plt.xlabel(\"Feature number\")\n",
    "plt.yticks(())\n",
    "plt.axis(\"tight\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True False  True  True False False False False False False False False\n",
      " False False False False False False False False False False False  True]\n"
     ]
    }
   ],
   "source": [
    "# RECURSIVE FEATURE SELECTION w/ random forest model\n",
    "# Compared to univariate feature selection, model-based feature selection consider all feature at once, thus can capture interactions. \n",
    "model_tree = RandomForestClassifier(random_state=100, n_estimators=50) #fit model\n",
    "sel_rfe_tree = RFE(estimator=model_tree, n_features_to_select=4, step=1) #define recursive elimination\n",
    "X_train_rfe_tree = sel_rfe_tree.fit_transform(X_train, y_train) #fit model and transform w/ new features\n",
    "print(sel_rfe_tree.get_support()) #output shows which features are selected "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.12140574 0.05807571 0.27409467 0.21186512 0.0109462  0.00724534\n",
      " 0.03065725 0.01678772 0.02334842 0.01800926 0.00732635 0.0118654\n",
      " 0.01072565 0.02077006 0.01442141 0.02742221 0.01559849 0.0160765\n",
      " 0.01209733 0.01642609 0.01415509 0.02777367 0.01103351 0.02187282]\n",
      "[ True  True  True  True False False False False False False False False\n",
      " False False False False False False False False False False False False]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=50, random_state=100)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SELECT FROM MODEL prunes features based on threshold\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "model_tree = RandomForestClassifier(random_state=100, n_estimators=50)\n",
    "model_tree.fit(X_train, y_train)\n",
    "print(model_tree.feature_importances_)\n",
    "sel_model_tree = SelectFromModel(estimator=model_tree, prefit=True, threshold='mean')  \n",
    "      # since we already fit the data, we specify prefit option here\n",
    "      # Features whose importance is greater or equal to the threshold are kept while the others are discarded.\n",
    "X_train_sfm_tree = sel_model_tree.transform(X_train)\n",
    "print(sel_model_tree.get_support()) #print which features were selected \n",
    "\n",
    "#create new model with paired down features\n",
    "model_tree_2 = RandomForestClassifier(random_state=100, n_estimators=50)\n",
    "model_tree_2.fit(X_train_sfm_tree, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[13  0  0]\n",
      " [ 0 13  0]\n",
      " [ 0  1 11]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        13\n",
      "           1       0.93      1.00      0.96        13\n",
      "           2       1.00      0.92      0.96        12\n",
      "\n",
      "    accuracy                           0.97        38\n",
      "   macro avg       0.98      0.97      0.97        38\n",
      "weighted avg       0.98      0.97      0.97        38\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# evaluation of accuracy of model before features selection\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "predict = model_tree.predict(X_test)\n",
    "print(confusion_matrix(y_test, predict))\n",
    "print(classification_report(y_test, predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38, 24)\n",
      "(38, 4)\n"
     ]
    }
   ],
   "source": [
    "# evaluation of accuracy after feature selecton (make sure to transform test data! use different dataset)\n",
    "X_test_sfm = sel_model_tree.transform(X_test)\n",
    "print(X_test.shape)\n",
    "print(X_test_sfm.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[13  0  0]\n",
      " [ 0 13  0]\n",
      " [ 0  2 10]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        13\n",
      "           1       0.87      1.00      0.93        13\n",
      "           2       1.00      0.83      0.91        12\n",
      "\n",
      "    accuracy                           0.95        38\n",
      "   macro avg       0.96      0.94      0.95        38\n",
      "weighted avg       0.95      0.95      0.95        38\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predict = model_tree_2.predict(X_test_sfm)\n",
    "print(confusion_matrix(y_test, predict))\n",
    "print(classification_report(y_test, predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time to compute the importances: 2.298 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "feature 0     0.023684\n",
       "feature 1     0.000000\n",
       "feature 2     0.113158\n",
       "feature 3     0.286842\n",
       "feature 4     0.000000\n",
       "feature 5     0.000000\n",
       "feature 6     0.007895\n",
       "feature 7     0.000000\n",
       "feature 8     0.002632\n",
       "feature 9     0.000000\n",
       "feature 10    0.000000\n",
       "feature 11    0.000000\n",
       "feature 12    0.000000\n",
       "feature 13    0.000000\n",
       "feature 14    0.000000\n",
       "feature 15    0.000000\n",
       "feature 16    0.000000\n",
       "feature 17    0.000000\n",
       "feature 18    0.000000\n",
       "feature 19    0.000000\n",
       "feature 20    0.000000\n",
       "feature 21    0.000000\n",
       "feature 22    0.000000\n",
       "feature 23    0.010526\n",
       "dtype: float64"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# FEATURE IMPORTANCES w/ permutation\n",
    "import time\n",
    "import pandas as pd\n",
    "from sklearn.inspection import permutation_importance\n",
    "feature_names = [f\"feature {i}\" for i in range(X.shape[1])]\n",
    "\n",
    "\n",
    "forest = RandomForestClassifier(random_state=0)\n",
    "forest.fit(X_train, y_train)\n",
    "\n",
    "start_time = time.time()\n",
    "result = permutation_importance(\n",
    "    forest, X_test, y_test, n_repeats=10, random_state=42, n_jobs=2\n",
    ")\n",
    "elapsed_time = time.time() - start_time\n",
    "print(f\"Elapsed time to compute the importances: {elapsed_time:.3f} seconds\")\n",
    "\n",
    "forest_importances = pd.Series(result.importances_mean, index=feature_names)\n",
    "forest_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SEQUENTIAL FEATURE SELECTION\n",
    "# https://www.kdnuggets.com/2018/06/step-forward-feature-selection-python.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score as acc\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as sfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset shape: (3673, 11) (3673,)\n",
      "Testing dataset shape: (1225, 11) (1225,)\n"
     ]
    }
   ],
   "source": [
    "# Read data\n",
    "df = pd.read_csv('winequality-white.csv', sep=';')\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df.values[:,:-1], #takes all columns except the last one\n",
    "    df.values[:,-1:], #takes the last column\n",
    "    test_size=0.25,\n",
    "    random_state=42)\n",
    "\n",
    "y_train = y_train.ravel()\n",
    "y_test = y_test.ravel()\n",
    "\n",
    "print('Training dataset shape:', X_train.shape, y_train.shape)\n",
    "print('Testing dataset shape:', X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.36</td>\n",
       "      <td>20.7</td>\n",
       "      <td>0.045</td>\n",
       "      <td>45.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>1.0010</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.45</td>\n",
       "      <td>8.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.049</td>\n",
       "      <td>14.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.9940</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.49</td>\n",
       "      <td>9.5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.1</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.40</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.050</td>\n",
       "      <td>30.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.9951</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.44</td>\n",
       "      <td>10.1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.9956</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.9956</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.0              0.27         0.36            20.7      0.045   \n",
       "1            6.3              0.30         0.34             1.6      0.049   \n",
       "2            8.1              0.28         0.40             6.9      0.050   \n",
       "3            7.2              0.23         0.32             8.5      0.058   \n",
       "4            7.2              0.23         0.32             8.5      0.058   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 45.0                 170.0   1.0010  3.00       0.45   \n",
       "1                 14.0                 132.0   0.9940  3.30       0.49   \n",
       "2                 30.0                  97.0   0.9951  3.26       0.44   \n",
       "3                 47.0                 186.0   0.9956  3.19       0.40   \n",
       "4                 47.0                 186.0   0.9956  3.19       0.40   \n",
       "\n",
       "   alcohol  quality  \n",
       "0      8.8        6  \n",
       "1      9.5        6  \n",
       "2     10.1        6  \n",
       "3      9.9        6  \n",
       "4      9.9        6  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   35.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:   60.0s finished\n",
      "\n",
      "[2022-02-03 13:24:24] Features: 1/5 -- score: 0.4960451537563254[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:   26.6s finished\n",
      "\n",
      "[2022-02-03 13:24:51] Features: 2/5 -- score: 0.544791191681032[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.7s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:   24.6s finished\n",
      "\n",
      "[2022-02-03 13:25:16] Features: 3/5 -- score: 0.607404400452279[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:   21.5s finished\n",
      "\n",
      "[2022-02-03 13:25:37] Features: 4/5 -- score: 0.6297217742682905[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.7s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:   18.5s finished\n",
      "\n",
      "[2022-02-03 13:25:56] Features: 5/5 -- score: 0.6384318523049546"
     ]
    }
   ],
   "source": [
    "# Build RF classifier to use in feature selection\n",
    "clf = RandomForestClassifier(n_estimators=100, n_jobs=-1)\n",
    "\n",
    "# Build step forward feature selection\n",
    "sfs1 = sfs(clf,\n",
    "           k_features=5,\n",
    "           forward=True,\n",
    "           floating=False,\n",
    "           verbose=2,\n",
    "           scoring='accuracy',\n",
    "           cv=5)\n",
    "\n",
    "# Perform SFFS\n",
    "sfs1 = sfs1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 3, 5, 7, 10]\n"
     ]
    }
   ],
   "source": [
    "# Which features?\n",
    "feat_cols = list(sfs1.k_feature_idx_)\n",
    "print(feat_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy on selected features: 0.562\n",
      "Testing accuracy on selected features: 0.519\n"
     ]
    }
   ],
   "source": [
    "# Build full model with selected features\n",
    "clf = RandomForestClassifier(n_estimators=1000, random_state=42, max_depth=4)\n",
    "clf.fit(X_train[:, feat_cols], y_train)\n",
    "\n",
    "y_train_pred = clf.predict(X_train[:, feat_cols])\n",
    "print('Training accuracy on selected features: %.3f' % acc(y_train, y_train_pred))\n",
    "\n",
    "y_test_pred = clf.predict(X_test[:, feat_cols])\n",
    "print('Testing accuracy on selected features: %.3f' % acc(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy on all features: 0.566\n",
      "Testing accuracy on all features: 0.509\n"
     ]
    }
   ],
   "source": [
    "# Build full model on ALL features, for comparison\n",
    "clf = RandomForestClassifier(n_estimators=1000, random_state=42, max_depth=4)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = clf.predict(X_train)\n",
    "print('Training accuracy on all features: %.3f' % acc(y_train, y_train_pred))\n",
    "\n",
    "y_test_pred = clf.predict(X_test)\n",
    "print('Testing accuracy on all features: %.3f' % acc(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (sklearn_env)",
   "language": "python",
   "name": "sklearn_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
